{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f129f3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.resnet50_backbone import ResNet50Backbone\n",
    "from src.data_loader import ShanghaiTechDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c753fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = ResNet50Backbone()\n",
    "model.load_state_dict(torch.load(\"../models/resnet50_finetuned.pth\"))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "val_dataset = ShanghaiTechDataset(\"../data/ShanghaiTech\", part=\"part_A\", split=\"test_data\", transform=transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1)\n",
    "\n",
    "mae = mse = 0\n",
    "with torch.no_grad():\n",
    "    for img, count_map in val_loader:\n",
    "        count = count_map.sum(dim=(1,2)).unsqueeze(1).float()\n",
    "        output = model(img)\n",
    "        mae += torch.abs(output - count).item()\n",
    "        mse += ((output - count)**2).item()\n",
    "\n",
    "print(\"MAE:\", mae / len(val_dataset))\n",
    "print(\"RMSE:\", (mse / len(val_dataset))**0.5)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
